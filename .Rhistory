tunegrid <- expand.grid(.mtry=c(1:15))
rf_tuned <- train(diabetes~., data=data.training,
method="rf", tuneGrid=tunegrid,trControl=control)
rf_tuned
# On observe dans notre cas que la meilleure valeur pour l'hyperparamètre "mtry" est 9 entre 1 et 15.
pred <- predict(rf_tuned, newdata=data.test)#Prédiction sur l'ensemble de test
pred
data.test$diabetes
evaluator(rf_tuned,data.test)#Résultat
#KNN
#On reprend la configuration du Random Forest en changeant les hyperparamètres à optimiser
set.seed(0)
tunegrid <- expand.grid(.k=c(1:100))
knn_tuned <- train(diabetes~., data=data.training,
method="knn", tuneGrid=tunegrid,trControl=control)
knn_tuned#La meilleure valeur pour l'hyperparamètre "k" est 12
pred <- predict(knn_tuned, newdata=data.test)#Prédiction sur l'ensemble de test
pred
data.test$diabetes
evaluator(knn_tuned,data.test)#Résultat
#rpart2
set.seed(0)
tunegrid <- expand.grid(.maxdepth=c(1:15))
rpart2_tuned <- train(diabetes~., data=data.training,
method="rpart2", tuneGrid=tunegrid,trControl=control)
rpart2_tuned#La meilleure valeur pour l'hyperparamètre "maxdepth" est 3
pred <- predict(rpart2_tuned, newdata=data.test)#Prédiction sur l'ensemble de test
pred
data.test$diabetes
evaluator(rpart2_tuned,data.test)#Résultat
#EX4
#RANK METHOD
weights <- information.gain(diabetes~., PimaIndiansDiabetes)
library(FSelector)
weights
#EX4
#RANK METHOD
weights <- information.gain(diabetes~., PimaIndiansDiabetes)
weights
#Gardons les attributs ayant un gain supérieure ) 0.04 à savoir insulin, age et glucose
subset <- cutoff.k(weights, 3)
f <- as.simple.formula(subset, "diabetes")
f
#Gardons les attributs ayant un gain supérieure ) 0.04 à savoir insulin, age et glucose
subset <- cutoff.k(weights, 4)
f <- as.simple.formula(subset, "diabetes")
f
#Entrainons notre modèle en considérant uniquement les 4 attributs cités ci-dessus dans le dataset
rf_tuned <- train(diabetes~glucose+mass+age+insulin, data=data.training,
method="rpart2", tuneGrid=tunegrid,trControl=control)
rf_tuned
#Entrainons notre modèle en considérant uniquement les 4 attributs cités ci-dessus dans le dataset
rf_tuned <- train(diabetes~glucose+mass+age+insulin, data=data.training,
method="rpart2", tuneGrid=tunegrid,trControl=control)
rf_tuned #on remarque que la vale
pred <- predict(rf_tuned, newdata=data.test)#Prédiction sur l'ensemble de test
pred
data.test$diabetes
evaluator(rf_tuned,data.test)
evaluatorSubset <- function(subset) {
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
DT <-train(PimaIndiansDiabetes[, 1:8], PimaIndiansDiabetes[, 9],
method="rpart2")
accuracy <- max(DT$results$Accuracy)
return(accuracy)
}
subset <- forward.search(names(PimaIndiansDiabetes)[-9], evaluatorSubset)
f <- as.simple.formula(subset, "diabetes")
print(f)#pressure + mass
subset <- forward.search(names(PimaIndiansDiabetes)[-9], evaluatorSubset)
f <- as.simple.formula(subset, "diabetes")
print(f)#pressure + mass
#FORWARD SEARCH
set_seed(0)
#FORWARD SEARCH
set.seed(0)
evaluatorSubset <- function(subset) {
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
DT <-train(PimaIndiansDiabetes[, 1:8], PimaIndiansDiabetes[, 9],
method="rpart2")
accuracy <- max(DT$results$Accuracy)
return(accuracy)
}
subset <- forward.search(names(PimaIndiansDiabetes)[-9], evaluatorSubset)
f <- as.simple.formula(subset, "diabetes")
print(f)#pressure + mass
#FORWARD SEARCH
set.seed(0)
evaluatorSubset <- function(subset) {
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
DT <-train(PimaIndiansDiabetes[, 1:8], PimaIndiansDiabetes[, 9],
method="rpart2")
accuracy <- max(DT$results$Accuracy)
return(accuracy)
}
subset <- forward.search(names(PimaIndiansDiabetes)[-9], evaluatorSubset)
f <- as.simple.formula(subset, "diabetes")
print(f)#pressure + mass
subset <- cfs(diabetes~., PimaIndiansDiabetes)
f <- as.simple.formula(subset, "diabetes")
print(f)
subset <- forward.search(names(PimaIndiansDiabetes)[-9], evaluatorSubset)
f <- as.simple.formula(subset, "diabetes")
print(f)#pressure
#FORWARD SEARCH
set.seed(0)
evaluatorSubset <- function(subset) {
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
DT <-train(PimaIndiansDiabetes[, 1:8], PimaIndiansDiabetes[, 9],
method="rpart2")
accuracy <- max(DT$results$Accuracy)
return(accuracy)
}
subset <- forward.search(names(PimaIndiansDiabetes)[-9], evaluatorSubset)
f <- as.simple.formula(subset, "diabetes")
print(f)#pressure
set.seed(0)
subset <- forward.search(names(PimaIndiansDiabetes)[-9], evaluatorSubset)
f <- as.simple.formula(subset, "diabetes")
print(f)#pressure
set.seed(0)
subset <- backward.search(names(PimaIndiansDiabetes)[-9], evaluatorSubset)
f <- as.simple.formula(subset, "diabetes")
print(f)#pressure
set.seed(0)
subset <- backward.search(names(PimaIndiansDiabetes)[-9], evaluatorSubset)
f <- as.simple.formula(subset, "diabetes")
print(f)#pressure
#On obtient les paramètres pressure
rpart2_tuned <- train(diabetes~pressure, data=data.training,
method="rpart2", tuneGrid=tunegrid,trControl=control)
rpart2_tuned
# On observe dans notre cas que la meilleure valeur pour l'hyperparamètre "maxdepth" est 2 entre 1 et 15 ce qui est différent de ce que l'on avait avec tous les attributs
pred <- predict(rpart2_tuned, newdata=data.test)#Prédiction sur l'ensemble de test
pred
data.test$diabetes
evaluator(rpart2_tuned,data.test)#Résultat Comparaison Tous les attributs --> 2 attributs
#On obtient les paramètres pressure
rpart2_tuned <- train(diabetes~pressure, data=data.training,
method="rpart2", tuneGrid=tunegrid,trControl=control)
rpart2_tuned
# On observe dans notre cas que la meilleure valeur pour l'hyperparamètre "maxdepth" est 2 entre 1 et 15 ce qui est différent de ce que l'on avait avec tous les attributs
pred <- predict(rpart2_tuned, newdata=data.test)#Prédiction sur l'ensemble de test
pred
data.test$diabetes
evaluator(rpart2_tuned,data.test)#Résultat Comparaison Tous les attributs --> 2 attributs
set.seed(0)
subset <- backward.search(names(PimaIndiansDiabetes)[-9], evaluatorSubset)
f <- as.simple.formula(subset, "diabetes")
print(f)#pressure
#On obtient les paramètres pressure
rpart2_tuned <- train(diabetes~ pregnant + pressure + triceps + insulin + mass + pedigree + age, data=data.training,
method="rpart2", tuneGrid=tunegrid,trControl=control)
rpart2_tuned
# On observe dans notre cas que la meilleure valeur pour l'hyperparamètre "maxdepth" est 6 entre 1 et 15 ce qui est différent de ce que l'on avait avec tous les attributs
pred <- predict(rpart2_tuned, newdata=data.test)#Prédiction sur l'ensemble de test
pred
data.test$diabetes
evaluator(rpart2_tuned,data.test)#Résultat Comparaison Tous les attributs --> 2 attributs
evaluatorSubset <- function(subset) {
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
DT <-train(PimaIndiansDiabetes[, 1:8], PimaIndiansDiabetes[, 9],
method="rpart2")
accuracy <- max(DT$results$Accuracy)
return(accuracy)
}
set.seed(0)
subset <- backward.search(names(PimaIndiansDiabetes)[-9], evaluatorSubset)
f <- as.simple.formula(subset, "diabetes")
print(f)# pregnant, pressure, triceps, insulin, mass, pedigree, age
#On obtient les paramètres pressure
rpart2_tuned <- train(diabetes~ pregnant + pressure + triceps + insulin + mass + pedigree + age, data=data.training,
method="rpart2", tuneGrid=tunegrid,trControl=control)
rpart2_tuned
# On observe dans notre cas que la meilleure valeur pour l'hyperparamètre "maxdepth" est 6 entre 1 et 15 ce qui est différent de ce que l'on avait avec tous les attributs
pred <- predict(rpart2_tuned, newdata=data.test)#Prédiction sur l'ensemble de test
pred
data.test$diabetes
evaluator(rpart2_tuned,data.test)#Résultat Comparaison Tous les attributs --> 7 attributs
install.packages("igraph")
install.packages("iGraph")
install.packages("Igraph")
install.packages("IGraph")
install.packages("igraph")
library(igraph)
install.packages("igraph")
library(igraph)
install.packages("arules")
install.packages("arules")
install.packages("arules")
rules = apriori(data("Groceries"))
#Clustering
library(arules)
rules = apriori(data("Groceries"))
install.packages("arules")
#Clustering
library(arules)
rules = apriori(data("Groceries"))
remove.packages("arules")
#Clustering
library(arules)
install.packages("arules")
#Clustering
library(arules)
update.packages("Matrix")
#Clustering
library(arules)
update.packages("Matrix")
library(Matrix)
remove.packages("Matrix")
#Clustering
library(arules)
update.packages("Matrix")
#Clustering
library(arules)
remove.packages("Matrix")
update.packages("Matrix")
#Clustering
library(arules)
#Clustering
library(arules)
setwd("h:/Desktop/ING3/S1/Ars/PROJET")
library(igraph)
data = read.table("h:/Desktop/ING3/S1/Ars/PROJET/ml-100k/u.data")
View(data)
#V1 : USER ID, les id sont distribués de 1 à nb de user (943)
#V2 : ITEM ID #Les items correspondent à des films et on dispose du détail de ces films dans le fichier u.item
#les id sont distribués de 1 à nb d'item (1682)
#V3 : RATING
#V4 : timestamp : temps écoulé entre le 1er janvier 1970 et la date de rentrée de la note
max(data["V3"])#Le Rating correspond donc à une note sur 5, note entière et allant de 1 à 5
nb_user = length(unique(data[["V1"]]))#On a bien 943 USER qui notent plusieurs "item"
nb_item = length(unique(data[["V2"]]))#1682 film
A = matrix(0,nb_user,nb_item) #Matrice qui comportera en ligne les user, en colonne les item et en coeff les notes
for(i in 1:length(data)){
user_id = as.numeric(data[i,]["V1"])
item_id = as.numeric(data[i,]["V2"])
rating = as.numeric(data[i,]["V3"])
A[user_id,item_id] = rating
}
#RECONSTITUTION DU GRAPH
g = graph_from_incidence_matrix(A,weighted = TRUE)
plot(g)
length(V(g)) #On a bien 943+1682 noeuds
length(E(g)) #On seulement 4 liens BIZARRE
g
V(g)
V(g)$2000
V(g)[[2625]]
V(g)[[2624]]
V(g)[[2624]]$id
V(g)[[2]]
length(V(g)) #On a bien 943+1682 noeuds
length(E(g)) #On seulement 4 liens BIZARRE
#RECONSTITUTION DU GRAPH
g = graph_from_incidence_matrix(t(A),weighted = TRUE)
plot(g)
length(V(g)) #On a bien 943+1682 noeuds
length(E(g)) #On seulement 4 liens BIZARRE
for(i in 1:nb_user){
for(j in nb_user+1:nb_total){
B[i,j] = A[i,j-nb_user]
B[j,i] = A[i,j-nb_user]
}
}
#Les fonctions sont pas adaptés donc go faire à la main
nb_total = nb_user+nb_item
for(i in 1:nb_user){
for(j in nb_user+1:nb_total){
B[i,j] = A[i,j-nb_user]
B[j,i] = A[i,j-nb_user]
}
}
B = matrix(0,nb_total,nb_total) #On va créer une matrice B symétrique comportant à la fois les items et les id
for(i in 1:nb_user){
for(j in nb_user+1:nb_total){
B[i,j] = A[i,j-nb_user]
B[j,i] = A[i,j-nb_user]
}
}
for(i in 1:nb_user){
for(j in nb_user+1:nb_total){
B[i,j] = A[i,j-nb_user]
B[j,i] = A[i,j-nb_user]
print("ok")
}
}
nb_total - nb_user
dim(A)
for(i in 1:nb_user){
for(j in nb_user+1:nb_total){
B[i,j] = A[i,j-nb_user]
B[j,i] = A[i,j-nb_user]
print(j-nb_user)
}
}
for(i in 1:nb_user){
for(j in nb_user+1:nb_total){
B[i,j] = A[i,j-nb_user]
B[j,i] = A[i,j-nb_user]
print(j-nb_user)
print(i)
}
}
for(i in 1:nb_user){
for(j in nb_user+1:nb_total-1){
B[i,j] = A[i,j-nb_user]
B[j,i] = A[i,j-nb_user]
print(j-nb_user)
print(i)
}
}
1682-944
A[nb_total-nb_user]
A[1,nb_total-nb_user]
A[2,nb_total-nb_user]
for(i in 1:nb_user){
for(j in nb_user+1:nb_total){
B[i,j] = A[i,j-nb_user]
#B[j,i] = A[i,j-nb_user]
}
}
nb_user+1-nb_user
nb_total-nb_user
dim(B)
setwd("h:/Desktop/ING3/S1/Ars/PROJET")
library(igraph)
data = read.table("h:/Desktop/ING3/S1/Ars/PROJET/ml-100k/u.data")
View(data)
#V1 : USER ID, les id sont distribués de 1 à nb de user (943)
#V2 : ITEM ID #Les items correspondent à des films et on dispose du détail de ces films dans le fichier u.item
#les id sont distribués de 1 à nb d'item (1682)
#V3 : RATING
#V4 : timestamp : temps écoulé entre le 1er janvier 1970 et la date de rentrée de la note
max(data["V3"])#Le Rating correspond donc à une note sur 5, note entière et allant de 1 à 5
nb_user = length(unique(data[["V1"]]))#On a bien 943 USER qui notent plusieurs "item"
nb_item = length(unique(data[["V2"]]))#1682 film
A = matrix(0,nb_user,nb_item) #Matrice qui comportera en ligne les user, en colonne les item et en coeff les notes
for(i in 1:length(data)){
user_id = as.numeric(data[i,]["V1"])
item_id = as.numeric(data[i,]["V2"])
rating = as.numeric(data[i,]["V3"])
A[user_id,item_id] = rating
}
View(A)
#RECONSTITUTION DU GRAPH
g = graph_from_incidence_matrix(A,weighted = TRUE)
plot(g)
g
length(V(g)) #On a bien 943+1682 noeuds
length(E(g)) #On seulement 4 liens BIZARRE
#Les fonctions sont pas adaptés donc go faire à la main
nb_total = nb_user+nb_item
B = matrix(0,nb_total,nb_total) #On va créer une matrice B symétrique comportant à la fois les items et les id
for(i in 1:nb_user){
for(j in nb_user+1:nb_total){
B[i,j] = A[i,j-nb_user]
B[j,i] = A[i,j-nb_user]
}
}
for(i in 1:nb_user){
for(j in nb_user+1:nb_total){
print(i,j)
B[i,j] = A[i,j-nb_user]
B[j,i] = A[i,j-nb_user]
}
}
for(i in 1:nb_user){
for(j in nb_user+1:nb_total){
print(i)
print(j)
B[i,j] = A[i,j-nb_user]
B[j,i] = A[i,j-nb_user]
}
}
for(i in 1:nb_user){
for(j in (nb_user+1):nb_total){
print(i)
print(j)
B[i,j] = A[i,j-nb_user]
B[j,i] = A[i,j-nb_user]
}
}
View(B)
B[196,242+943]
g2 = graph_from_adjacency_matrix(B,weighted = TRUE)
plot(g2)
E(g2)
V(g2)
E(g2)
#RECONSTITUTION DU GRAPH
g = graph_from_incidence_matrix(A,weighted = TRUE)
plot(g)
g
length(V(g)) #On a bien 943+1682 noeuds
length(E(g)) #On seulement 4 liens BIZARRE
B[22,1320]
B[244,994]
B[186,1245]
length(E(g))
# # 1 à 943 ==> les id des users
# # 944 à 2625 ==> les id des items
#
# for(i in 1:nb_user){
#   for(j in (nb_user+1):nb_total){
#     B[i,j] = A[i,j-nb_user]
#     B[j,i] = A[i,j-nb_user]
#   }
# }
#
g2 = graph_from_adjacency_matrix(B,mode = "undirected",weighted = TRUE)
plot(g2)
E(g2)
V(g2) #Même constat que pour l'autre méthode
#   for(j in (nb_user+1):nb_total){
#     B[i,j] = A[i,j-nb_user]
#     B[j,i] = A[i,j-nb_user]
#   }
# }
#
# g2 = graph_from_adjacency_matrix(B,mode = "undirected",weighted = TRUE)
# plot(g2)
# E(g2)
# V(g2) #Même constat que pour l'autre méthode
E(g2)$weighted
#   for(j in (nb_user+1):nb_total){
#     B[i,j] = A[i,j-nb_user]
#     B[j,i] = A[i,j-nb_user]
#   }
# }
#
# g2 = graph_from_adjacency_matrix(B,mode = "undirected",weighted = TRUE)
# plot(g2)
# E(g2)
# V(g2) #Même constat que pour l'autre méthode
E(g2)$weight
#   for(j in (nb_user+1):nb_total){
#     B[i,j] = A[i,j-nb_user]
#     B[j,i] = A[i,j-nb_user]
#   }
# }
#
# g2 = graph_from_adjacency_matrix(B,mode = "undirected",weighted = TRUE)
# plot(g2)
# E(g2)
# V(g2) #Même constat que pour l'autre méthode
E(g)$weight
col = c()
for(i in 1:nb_user){
col = c(col,"U"+toString(i))
}
for(i in 1:nb_user){
col = c(col,paste("U",toString(i)))
}
col
row = c()
for(i in 1:nb_user){
row = c(row,gsub(" ","",paste("U",toString(i))))
}
row
cols = c()
for(i in 1:nb_item){
cols = c(cols,gsub(" ","",paste("U",toString(i))))
}
colnames[A] = cols
colnames(A) = cols
rownames(A) = rows
rows = c()
for(i in 1:nb_user){
rows = c(rows,gsub(" ","",paste("U",toString(i))))
}
rownames(A) = rows
View(A)
rows = c()
for(i in 1:nb_user){
rows = c(rows,gsub(" ","",paste("U",toString(i))))
}
cols = c()
for(i in 1:nb_item){
cols = c(cols,gsub(" ","",paste("I",toString(i))))
}
colnames(A) = cols
rownames(A) = rows
View(A)
#RECONSTITUTION DU GRAPH
g = graph_from_incidence_matrix(A,weighted = TRUE)
plot(g)
g
V(g)
V(g)["2000"]
V(g)[2000]
V(g)[2625]
length(A[A>0])
length(data)
dim(data)
dim(data)[1]
A = matrix(0,nb_user,nb_item) #Matrice qui comportera en ligne les user, en colonne les item et en coeff les notes
for(i in 1:length(dim(data)[1])){
user_id = as.numeric(data[i,]["V1"])
item_id = as.numeric(data[i,]["V2"])
rating = as.numeric(data[i,]["V3"])
A[user_id,item_id] = rating
}
View(A)
length(A[A>0])
dim(data[1])
dim(data)[1]
